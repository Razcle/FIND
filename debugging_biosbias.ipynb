{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Biosbias\n",
    "- **Task**: For Biosbias, the task is predicting the occupation of a given bio paragraph, i.e., whether the person is 'a surgeon' (class 0) or 'a nurse' (class 1).\n",
    "- **Problem**: Due to the gender imbalance in each occupation, a classifier usually exploits gender information when making predictions. As a result, bios of female surgeons and male nurses are often misclassified. We quantify the bias of the model using two metrics: FPED and FNED (For details, please see [Dixon et al., 2018](https://dl.acm.org/doi/pdf/10.1145/3278721.3278729)). \n",
    "- **Solution**: To reduce the model's bias, we use our framework to identify the features which detect gender information rather than occupation and disable such features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Notebook setup\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [14, 7]\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set random seed to create reproducable results\n",
    "the_seed = 1234\n",
    "np.random.seed(the_seed)\n",
    "random.seed(the_seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(the_seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'preprocessed_data/'\n",
    "MAIN_DATASET = 'Biosbias2'\n",
    "SECOND_DATASET = None\n",
    "THIRD_DATASET = None\n",
    "GENDER_BIAS = True\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "EMBEDDING_PATH = f\"../../CNNAnalysis/data/glove/glove.6B.{EMBEDDING_DIM}d.txt\" # Path to your glove embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'trained_models/'\n",
    "MODEL_ARCH = 'CNN'\n",
    "MAXLEN = 150\n",
    "FILTERS = [(10, 2), (10, 3), (10, 4)] # Ten filters of each window size [2,3,4]\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "262it [00:00, 2601.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:55, 7144.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "# 0. Load GloVe embeddings\n",
    "embedding_matrix, vocab_size, index2word, word2index = find.get_embedding_matrix(EMBEDDING_PATH, EMBEDDING_DIM, pad_initialisation = \"zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3832/3832 [00:07<00:00, 492.91it/s]\n",
      "100%|██████████| 1277/1277 [00:02<00:00, 467.36it/s]\n",
      "100%|██████████| 1278/1278 [00:02<00:00, 480.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load datasets and prepare inputs\n",
    "# 1.1 Main dataset\n",
    "data_1 = pickle.load(open(DATA_PATH + f'all_data_{MAIN_DATASET}.pickle', 'rb'))\n",
    "class_names = data_1['class_names']\n",
    "X_train_1, X_validate_1, X_test_1 = find.get_data_matrix(data_1['text_train'], word2index, MAXLEN), \\\n",
    "                                    find.get_data_matrix(data_1['text_validate'], word2index, MAXLEN), \\\n",
    "                                    find.get_data_matrix(data_1['text_test'], word2index, MAXLEN)\n",
    "y_test_1 = data_1['y_test']\n",
    "gender_test_1 = data_1['gender_test'] if GENDER_BIAS else None\n",
    "\n",
    "# 1.2 Second dataset\n",
    "if SECOND_DATASET is not None:\n",
    "    data_2 = pickle.load(open(DATA_PATH + f'all_data_{SECOND_DATASET}.pickle', 'rb'))\n",
    "    X_test_2, y_test_2 = find.get_data_matrix(data_2['text_test'], word2index, MAXLEN), data_2['y_test']\n",
    "    gender_test_2 = data_2['gender_test'] if GENDER_BIAS else None\n",
    "else:\n",
    "    X_test_2, y_test_2, gender_test_2 = None, None, None\n",
    "\n",
    "# 1.3 Third dataset\n",
    "if THIRD_DATASET is not None:\n",
    "    data_3 = pickle.load(open(DATA_PATH + f'all_data_{THIRD_DATASET}.pickle', 'rb'))\n",
    "    X_test_3, y_test_3 = find.get_data_matrix(data_3['text_test'], word2index, MAXLEN), data_3['y_test']\n",
    "    gender_test_3 = data_3['gender_test'] if GENDER_BIAS else None\n",
    "else:\n",
    "    X_test_3, y_test_3, gender_test_2  = None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create the result directory\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "result_folder = MAIN_DATASET + '_' + MODEL_ARCH + '_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\") + '/'\n",
    "result_path = MODEL_PATH + result_folder\n",
    "os.mkdir(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 150, 300)     120000600   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 149, 10)      6010        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 148, 10)      9010        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 147, 10)      12010       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 10)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 10)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 10)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30)           0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_1 (MaskedDense)    (None, 2)            122         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 120,027,752\n",
      "Trainable params: 27,092\n",
      "Non-trainable params: 120,000,660\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3. Create a model\n",
    "if MODEL_ARCH == 'CNN':\n",
    "    model = find.get_CNN_model(vocab_size, EMBEDDING_DIM, embedding_matrix, MAXLEN, class_names, FILTERS)\n",
    "else:\n",
    "    assert False, f\"Unsupported model architecture: {MODEL_ARCH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3832 samples, validate on 1277 samples\n",
      "Epoch 1/300\n",
      " - 13s - loss: 0.3877 - acc: 0.8236 - val_loss: 0.1898 - val_acc: 0.9366\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18977, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 2/300\n",
      " - 12s - loss: 0.1461 - acc: 0.9517 - val_loss: 0.1362 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18977 to 0.13615, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 3/300\n",
      " - 13s - loss: 0.1070 - acc: 0.9653 - val_loss: 0.1168 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.13615 to 0.11684, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 4/300\n",
      " - 13s - loss: 0.0868 - acc: 0.9736 - val_loss: 0.1075 - val_acc: 0.9569\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11684 to 0.10746, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 5/300\n",
      " - 13s - loss: 0.0698 - acc: 0.9804 - val_loss: 0.0996 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.10746 to 0.09960, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 6/300\n",
      " - 12s - loss: 0.0584 - acc: 0.9856 - val_loss: 0.0957 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.09960 to 0.09566, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 7/300\n",
      " - 13s - loss: 0.0486 - acc: 0.9890 - val_loss: 0.0934 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.09566 to 0.09345, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 8/300\n",
      " - 13s - loss: 0.0401 - acc: 0.9922 - val_loss: 0.0898 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09345 to 0.08980, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 9/300\n",
      " - 13s - loss: 0.0337 - acc: 0.9948 - val_loss: 0.0913 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08980\n",
      "Epoch 10/300\n",
      " - 13s - loss: 0.0277 - acc: 0.9963 - val_loss: 0.0911 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08980\n",
      "Epoch 11/300\n",
      " - 12s - loss: 0.0232 - acc: 0.9977 - val_loss: 0.0847 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08980 to 0.08472, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 12/300\n",
      " - 12s - loss: 0.0191 - acc: 0.9992 - val_loss: 0.0856 - val_acc: 0.9624\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.08472\n",
      "Epoch 13/300\n",
      " - 12s - loss: 0.0168 - acc: 0.9990 - val_loss: 0.0895 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08472\n",
      "Epoch 14/300\n",
      " - 13s - loss: 0.0138 - acc: 0.9997 - val_loss: 0.0837 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08472 to 0.08372, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN.h5\n",
      "Epoch 15/300\n",
      " - 13s - loss: 0.0119 - acc: 0.9995 - val_loss: 0.0847 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08372\n",
      "Epoch 16/300\n",
      " - 13s - loss: 0.0100 - acc: 0.9997 - val_loss: 0.0869 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08372\n",
      "Epoch 17/300\n",
      " - 13s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9632\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08372\n"
     ]
    }
   ],
   "source": [
    "# 4. Train the model\n",
    "history = find.model_train(model, result_path + f'trained_{MODEL_ARCH}.h5', X_train_1, data_1['y_train'], X_validate_1, data_1['y_validate'], BATCH_SIZE, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate with the original test set:\n",
      "{'per_class': {0: {'all_positive': 714,\n",
      "                   'all_true': 731,\n",
      "                   'class_f1': 0.9550173010380623,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.9663865546218487,\n",
      "                   'class_recall': 0.9439124487004104,\n",
      "                   'true_positive': 690},\n",
      "               1: {'all_positive': 564,\n",
      "                   'all_true': 547,\n",
      "                   'class_f1': 0.9414941494149416,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.9273049645390071,\n",
      "                   'class_recall': 0.9561243144424132,\n",
      "                   'true_positive': 523}},\n",
      " 'total': {'accuracy': 0.9491392801251957,\n",
      "           'macro_f1': 0.9484294173731734,\n",
      "           'macro_precision': 0.9468457595804279,\n",
      "           'macro_recall': 0.9500183815714118,\n",
      "           'micro_f1': 0.9491392801251957,\n",
      "           'micro_precision': 0.9491392801251957,\n",
      "           'micro_recall': 0.9491392801251957}}\n",
      "FPR = 0.0560875512995896\n",
      "FNR = 0.043875685557586835\n",
      "\n",
      "Female prediction:\n",
      "{'per_class': {0: {'all_positive': 82,\n",
      "                   'all_true': 101,\n",
      "                   'class_f1': 0.8087431693989071,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.9024390243902439,\n",
      "                   'class_recall': 0.7326732673267327,\n",
      "                   'true_positive': 74},\n",
      "               1: {'all_positive': 517,\n",
      "                   'all_true': 498,\n",
      "                   'class_f1': 0.9655172413793104,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.9477756286266924,\n",
      "                   'class_recall': 0.9839357429718876,\n",
      "                   'true_positive': 490}},\n",
      " 'total': {'accuracy': 0.9415692821368948,\n",
      "           'macro_f1': 0.8904547698898732,\n",
      "           'macro_precision': 0.9251073265084682,\n",
      "           'macro_recall': 0.8583045051493101,\n",
      "           'micro_f1': 0.9415692821368948,\n",
      "           'micro_precision': 0.9415692821368948,\n",
      "           'micro_recall': 0.9415692821368948}}\n",
      "FPR = 0.26732673267326734\n",
      "FNR = 0.01606425702811245\n",
      "\n",
      "Male prediction:\n",
      "{'per_class': {0: {'all_positive': 632,\n",
      "                   'all_true': 630,\n",
      "                   'class_f1': 0.976228209191759,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.9746835443037974,\n",
      "                   'class_recall': 0.9777777777777777,\n",
      "                   'true_positive': 616},\n",
      "               1: {'all_positive': 47,\n",
      "                   'all_true': 49,\n",
      "                   'class_f1': 0.6875000000000001,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.7021276595744681,\n",
      "                   'class_recall': 0.673469387755102,\n",
      "                   'true_positive': 33}},\n",
      " 'total': {'accuracy': 0.9558173784977909,\n",
      "           'macro_f1': 0.8319655006614769,\n",
      "           'macro_precision': 0.8384056019391328,\n",
      "           'macro_recall': 0.8256235827664399,\n",
      "           'micro_f1': 0.9558173784977909,\n",
      "           'micro_precision': 0.9558173784977909,\n",
      "           'micro_recall': 0.9558173784977909}}\n",
      "FPR = 0.022222222222222223\n",
      "FNR = 0.32653061224489793\n",
      "----------------------------------------------------\n",
      "FPED = 0.24510451045104514\n",
      "FNED = 0.31046635521678545\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate the model\n",
    "if not GENDER_BIAS:\n",
    "    find.evaluate_all(model, class_names, BATCH_SIZE, X_test_1, y_test_1, X_test_2, y_test_2, X_test_3, y_test_3, result_path = result_path, model_name = 'original')\n",
    "else:\n",
    "    find.evaluate_all_gender(model, class_names, BATCH_SIZE, X_test_1, y_test_1, gender_test_1, X_test_2, y_test_2, gender_test_2, result_path = result_path, model_name = 'original')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model understanding and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [00:00<00:00, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedded_text_input (InputLayer (None, 150, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 149, 10)      6010        embedded_text_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 148, 10)      9010        embedded_text_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 147, 10)      12010       embedded_text_input[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_4 (GlobalM (None, 10)           0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_5 (GlobalM (None, 10)           0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 10)           0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 30)           0           global_max_pooling1d_4[0][0]     \n",
      "                                                                 global_max_pooling1d_5[0][0]     \n",
      "                                                                 global_max_pooling1d_6[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 27,030\n",
      "Trainable params: 0\n",
      "Non-trainable params: 27,030\n",
      "__________________________________________________________________________________________________\n",
      "Num batches: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  7.36it/s]\n",
      "100%|██████████| 30/30 [02:43<00:00,  5.45s/it]\n",
      "100%|██████████| 30/30 [00:26<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# 6. Generate wordclouds\n",
    "settings = {\n",
    "    'model_arch': MODEL_ARCH,\n",
    "    'filters': FILTERS,\n",
    "    'maxlen': MAXLEN,\n",
    "    'result_path': result_path,\n",
    "    'index2word': index2word,\n",
    "    'embedding_dim': EMBEDDING_DIM,\n",
    "    'batch_size': BATCH_SIZE\n",
    "}\n",
    "all_wordclouds = find.generate_wordclouds(model, X_train_1, settings, max_examples = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get input from a human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_feature_enabled = [True for i in range(find.num_all_filters(FILTERS))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI components from ipywidgets\n",
    "import ipywidgets as wgt\n",
    "\n",
    "def update_screen(feature_idx):\n",
    "    show_action_panel(feature_idx)\n",
    "    wordcloud = all_wordclouds[feature_idx]\n",
    "    f, ax = plt.subplots()\n",
    "    plt.rcParams['figure.figsize'] = [14, 7]\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "    W = model.layers[-1].get_weights()[0] # For the final layer\n",
    "    weight_plot = find.visualize_weights(W, feature_idx, class_names, show = False)\n",
    "    plt.show()\n",
    "\n",
    "def update_action(action):\n",
    "    global feature_radio_button, is_feature_enabled\n",
    "    feature_idx = feature_radio_button.value\n",
    "    if action == 'enabled':\n",
    "        print('enable')\n",
    "        is_feature_enabled[feature_idx] = True\n",
    "    elif action == 'disabled':\n",
    "        print('disable')\n",
    "        is_feature_enabled[feature_idx] = False\n",
    "    else:\n",
    "        assert False\n",
    "    \n",
    "def show_action_panel(feature_idx):\n",
    "    global action_radio_button\n",
    "    action_radio_button.description = f'Current status of feature {feature_idx}:'\n",
    "    action_radio_button.value = 'enabled' if is_feature_enabled[feature_idx] else 'disabled'\n",
    "    \n",
    "feature_radio_button = wgt.RadioButtons(options=list(range(30)), value=0, description='Feature:', disabled=False)\n",
    "action_radio_button = wgt.RadioButtons(options=['enabled', 'disabled'],\n",
    "    value = 'enabled' if is_feature_enabled[feature_radio_button.value] else 'disabled',\n",
    "    description = f'Current status of feature {feature_radio_button.value}:',\n",
    "    style = {'description_width': 'initial'},\n",
    "    disabled = False\n",
    ")\n",
    "\n",
    "wgt.interactive_output(update_action, {'action':action_radio_button})\n",
    "out = wgt.interactive_output(update_screen, {'feature_idx':feature_radio_button})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd6187edd0649448206dbc9e0fd4ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(RadioButtons(description='Feature:', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Get input from a human (disabling some features)\n",
    "display(wgt.HBox([feature_radio_button, wgt.VBox([out, action_radio_button])]))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 30 features \n",
      "Enabled: 23 features \n",
      "Disabled: 7 features\n",
      "Disabled features: [0, 5, 8, 10, 14, 16, 26]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total: {len(is_feature_enabled)} features \\nEnabled: {sum(is_feature_enabled)} features \\nDisabled: {len(is_feature_enabled)-sum(is_feature_enabled)} features\")\n",
    "print(f\"Disabled features: {[i for i,s in enumerate(is_feature_enabled) if not s]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and fine-tuning an improved classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 150, 300)     120000600   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 149, 10)      6010        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 148, 10)      9010        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 147, 10)      12010       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 10)           0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 10)           0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 10)           0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30)           0           global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_2 (MaskedDense)    (None, 2)            122         concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 120,027,752\n",
      "Trainable params: 62\n",
      "Non-trainable params: 120,027,690\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 8. Create an improved model\n",
    "# 8.1 Copy the existing CNN features\n",
    "model_improved = find.get_CNN_model(vocab_size, EMBEDDING_DIM, embedding_matrix, MAXLEN, class_names, \n",
    "                                    FILTERS, trainable_filters = False)\n",
    "model_improved.set_weights(model.get_weights()) \n",
    "\n",
    "# 8.2 Apply human decisions to disable irrelevant features\n",
    "for idx, enable in enumerate(is_feature_enabled):\n",
    "    if not enable:\n",
    "        model_improved.layers[-1].disable_mask(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3832 samples, validate on 1277 samples\n",
      "Epoch 1/300\n",
      " - 8s - loss: 0.0460 - acc: 0.9927 - val_loss: 0.1176 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11765, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN_improved.h5\n",
      "Epoch 2/300\n",
      " - 7s - loss: 0.0412 - acc: 0.9945 - val_loss: 0.1181 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.11765\n",
      "Epoch 3/300\n",
      " - 8s - loss: 0.0388 - acc: 0.9940 - val_loss: 0.1187 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.11765\n",
      "Epoch 4/300\n",
      " - 7s - loss: 0.0365 - acc: 0.9945 - val_loss: 0.1171 - val_acc: 0.9491\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11765 to 0.11714, saving model to trained_models/Biosbias2_CNN_20200921022749/trained_CNN_improved.h5\n",
      "Epoch 5/300\n",
      " - 7s - loss: 0.0348 - acc: 0.9945 - val_loss: 0.1191 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.11714\n",
      "Epoch 6/300\n",
      " - 8s - loss: 0.0332 - acc: 0.9948 - val_loss: 0.1186 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.11714\n",
      "Epoch 7/300\n",
      " - 8s - loss: 0.0319 - acc: 0.9945 - val_loss: 0.1189 - val_acc: 0.9499\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11714\n"
     ]
    }
   ],
   "source": [
    "# 9. Fine-tuning the improved model\n",
    "history = find.model_train(model_improved, result_path + f'trained_{MODEL_ARCH}_improved.h5', X_train_1, data_1['y_train'], X_validate_1, data_1['y_validate'], BATCH_SIZE, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate with the original test set:\n",
      "{'per_class': {0: {'all_positive': 709,\n",
      "                   'all_true': 731,\n",
      "                   'class_f1': 0.9374999999999999,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.9520451339915373,\n",
      "                   'class_recall': 0.9233926128590971,\n",
      "                   'true_positive': 675},\n",
      "               1: {'all_positive': 569,\n",
      "                   'all_true': 547,\n",
      "                   'class_f1': 0.9193548387096774,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.9015817223198594,\n",
      "                   'class_recall': 0.9378427787934186,\n",
      "                   'true_positive': 513}},\n",
      " 'total': {'accuracy': 0.9295774647887324,\n",
      "           'macro_f1': 0.9287116661661686,\n",
      "           'macro_precision': 0.9268134281556983,\n",
      "           'macro_recall': 0.9306176958262579,\n",
      "           'micro_f1': 0.9295774647887324,\n",
      "           'micro_precision': 0.9295774647887324,\n",
      "           'micro_recall': 0.9295774647887324}}\n",
      "FPR = 0.07660738714090287\n",
      "FNR = 0.062157221206581355\n",
      "\n",
      "Female prediction:\n",
      "{'per_class': {0: {'all_positive': 109,\n",
      "                   'all_true': 101,\n",
      "                   'class_f1': 0.7904761904761906,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.7614678899082569,\n",
      "                   'class_recall': 0.8217821782178217,\n",
      "                   'true_positive': 83},\n",
      "               1: {'all_positive': 490,\n",
      "                   'all_true': 498,\n",
      "                   'class_f1': 0.9554655870445344,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.963265306122449,\n",
      "                   'class_recall': 0.9477911646586346,\n",
      "                   'true_positive': 472}},\n",
      " 'total': {'accuracy': 0.9265442404006677,\n",
      "           'macro_f1': 0.8734327836688796,\n",
      "           'macro_precision': 0.862366598015353,\n",
      "           'macro_recall': 0.8847866714382282,\n",
      "           'micro_f1': 0.9265442404006677,\n",
      "           'micro_precision': 0.9265442404006677,\n",
      "           'micro_recall': 0.9265442404006677}}\n",
      "FPR = 0.1782178217821782\n",
      "FNR = 0.05220883534136546\n",
      "\n",
      "Male prediction:\n",
      "{'per_class': {0: {'all_positive': 600,\n",
      "                   'all_true': 630,\n",
      "                   'class_f1': 0.9626016260162602,\n",
      "                   'class_name': 'surgeon',\n",
      "                   'class_precision': 0.9866666666666667,\n",
      "                   'class_recall': 0.9396825396825397,\n",
      "                   'true_positive': 592},\n",
      "               1: {'all_positive': 79,\n",
      "                   'all_true': 49,\n",
      "                   'class_f1': 0.640625,\n",
      "                   'class_name': 'nurse',\n",
      "                   'class_precision': 0.5189873417721519,\n",
      "                   'class_recall': 0.8367346938775511,\n",
      "                   'true_positive': 41}},\n",
      " 'total': {'accuracy': 0.9322533136966127,\n",
      "           'macro_f1': 0.8149334768067282,\n",
      "           'macro_precision': 0.7528270042194093,\n",
      "           'macro_recall': 0.8882086167800454,\n",
      "           'micro_f1': 0.9322533136966127,\n",
      "           'micro_precision': 0.9322533136966127,\n",
      "           'micro_recall': 0.9322533136966127}}\n",
      "FPR = 0.06031746031746032\n",
      "FNR = 0.16326530612244897\n",
      "----------------------------------------------------\n",
      "FPED = 0.11790036146471788\n",
      "FNED = 0.11105647078108352\n"
     ]
    }
   ],
   "source": [
    "# 10. Evaluate the improved model\n",
    "if not GENDER_BIAS:\n",
    "    find.evaluate_all(model_improved, class_names, BATCH_SIZE, X_test_1, y_test_1, X_test_2, y_test_2, X_test_3, y_test_3, result_path = result_path, model_name = 'debugged')\n",
    "else:\n",
    "    find.evaluate_all_gender(model_improved, class_names, BATCH_SIZE, X_test_1, y_test_1, gender_test_1, X_test_2, y_test_2, gender_test_2, result_path = result_path, model_name = 'debugged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
